{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VisionAirport"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports + Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from pyspark import SparkContext\n",
    "import numpy as np\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import col, desc, asc, lit\n",
    "from pyspark.sql import functions as F\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import rc\n",
    "import folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SC already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/senne/miniforge3/envs/tensorflow/lib/python3.9/site-packages/pyspark/sql/context.py:77: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    sc = SparkContext(\"local\").getOrCreate()\n",
    "except:\n",
    "    print(\"SC already exists\")\n",
    "sqlContext = SQLContext(sc)\n",
    "spark = SparkSession(sc)\n",
    "plt.style.use('ggplot')\n",
    "DATADIR = \"./data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Airport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "+--------------+------------+-----------+----+----+---------+---------+----+----+---+----------+\n",
      "|airport       |city        |country    |IATA|ICAO|lat      |lon      |alt |TZ  |dst|tz2       |\n",
      "+--------------+------------+-----------+----+----+---------+---------+----+----+---+----------+\n",
      "|Airport       |City        |Country    |IATA|ICAO|null     |null     |Alt |null|DST|Tz        |\n",
      "|Bamyan Airport|Bamyan      |Afghanistan|BIN |OABN|34.816666|67.816666|2550|4.5 |N  |Asia/Kabul|\n",
      "|Camp Bastion  |Camp Bastion|Afghanistan|null|OAZI|31.865557|64.195274|2808|4.5 |N  |Asia/Kabul|\n",
      "+--------------+------------+-----------+----+----+---------+---------+----+----+---+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# AIRPORT DATAFRAME\n",
    "\n",
    "airport_schema = StructType([\n",
    "    StructField('airport', StringType(), True),\n",
    "    StructField('city', StringType(), True),\n",
    "    StructField('country', StringType(), True),\n",
    "    StructField('IATA', StringType(), True),\n",
    "    StructField('ICAO', StringType(), True),\n",
    "    StructField('lat', FloatType(), True),\n",
    "    StructField('lon', FloatType(), True),\n",
    "    StructField('alt', StringType(), True),\n",
    "    StructField('TZ', FloatType(), True),\n",
    "    StructField('dst', StringType(), True),\n",
    "    StructField('tz2', StringType(), True),\n",
    "])\n",
    "\n",
    "\n",
    "airport_df = spark.read.csv(\n",
    "    \"./data/export_luchthavens.txt\", \n",
    "    # header=True,\n",
    "    sep=\"\\t\",\n",
    "    multiLine=True,\n",
    "    schema=airport_schema\n",
    ")\n",
    "\n",
    "try:\n",
    "    airport_df.write.parquet(\"aws/airport.parquet\")\n",
    "except:\n",
    "    print(\"\")\n",
    "airport_df.show(3, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (2640438435.py, line 55)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/yh/kcqcvv194vgf79tlydyy5n2w0000gn/T/ipykernel_15399/2640438435.py\"\u001b[0;36m, line \u001b[0;32m55\u001b[0m\n\u001b[0;31m    except:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "# WEATHER DATAFRAME\n",
    "\n",
    "weather_schema = StructType([\n",
    "    StructField('date', DateType(), True),\n",
    "    StructField('DDVEC', IntegerType(), True),\n",
    "    StructField('FHVEC', IntegerType(), True),\n",
    "    StructField('FG', IntegerType(), True),\n",
    "    StructField('FHX', IntegerType(), True),\n",
    "    StructField('FHXH', IntegerType(), True),\n",
    "    StructField('FHN', IntegerType(), True),\n",
    "    StructField('FHNH', IntegerType(), True),\n",
    "    StructField('FXX', IntegerType(), True),\n",
    "    StructField('FXXH', IntegerType(), True),\n",
    "    StructField('TG', IntegerType(), True),\n",
    "    StructField('TN', IntegerType(), True),\n",
    "    StructField('TNH', IntegerType(), True),\n",
    "    StructField('TX', IntegerType(), True),\n",
    "    StructField('TXH', IntegerType(), True),\n",
    "    StructField('T10N', IntegerType(), True),\n",
    "    StructField('T10NH', IntegerType(), True),\n",
    "    StructField('SQ', IntegerType(), True),\n",
    "    StructField('Q', IntegerType(), True),\n",
    "    StructField('DR', IntegerType(), True),\n",
    "    StructField('RH', IntegerType(), True),\n",
    "    StructField('RHX', IntegerType(), True),\n",
    "    StructField('RHXH', IntegerType(), True),\n",
    "    StructField('PG', IntegerType(), True),\n",
    "    StructField('PX', IntegerType(), True),\n",
    "    StructField('PXH', IntegerType(), True),\n",
    "    StructField('PN', IntegerType(), True),\n",
    "    StructField('PNH', IntegerType(), True),\n",
    "    StructField('VVN', IntegerType(), True),\n",
    "    StructField('VVNH', IntegerType(), True),\n",
    "    StructField('VVX', IntegerType(), True),\n",
    "    StructField('VVXH', IntegerType(), True),\n",
    "    StructField('NG', IntegerType(), True),\n",
    "    StructField('UG', IntegerType(), True),\n",
    "    StructField('UX', IntegerType(), True),\n",
    "    StructField('UXH', IntegerType(), True),\n",
    "    StructField('UN', IntegerType(), True),\n",
    "    StructField('UNH', IntegerType(), True),\n",
    "    StructField('EV2', IntegerType(), True),\n",
    "])\n",
    "\n",
    "weather_df = spark.read.csv(\n",
    "    \"./data/export_weer.txt\", \n",
    "    header=True,\n",
    "    sep=\"\\t\",\n",
    "    multiLine=True,\n",
    "    schema=weather_schema\n",
    ")\n",
    "\n",
    "try:\n",
    "    weather_df.write.parquet(\"aws/weather.parquet\")\n",
    "except:\n",
    "    print(\"\")\n",
    "weather_df.show(3, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUSTOMERS DATAFRAME\n",
    "\n",
    "customers_schema = StructType([\n",
    "    StructField('id', IntegerType(), True),\n",
    "    StructField('operation', FloatType(), True),\n",
    "    StructField('facilities', FloatType(), True),\n",
    "    StructField('shops', FloatType(), True),\n",
    "])\n",
    "\n",
    "\n",
    "customers_df = spark.read.csv(\n",
    "    \"./data/export_klant.csv\", \n",
    "    header=True,\n",
    "    sep=\";\",\n",
    "    multiLine=True,\n",
    "    schema=customers_schema\n",
    ")\n",
    "\n",
    "try:\n",
    "    customers_df.write.parquet(\"aws/customers.parquet\")\n",
    "except:\n",
    "    print(\"\")\n",
    "customers_df.show(3, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vertrek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertrek_schema = StructType([\n",
    "    StructField(\"Vluchtid\", IntegerType(), False),\n",
    "    StructField(\"Vliegtuigcode\",StringType(),True),\n",
    "    StructField(\"Terminal\", StringType(),True),\n",
    "    StructField(\"Gate\", StringType(), True),\n",
    "    StructField(\"Baan\", ShortType(), True),\n",
    "    StructField(\"Bezetting\", IntegerType(), True),\n",
    "    StructField(\"Vracht\", IntegerType(), True),\n",
    "    StructField(\"Vertrektijd\", TimestampType(), True)\n",
    "  ])\n",
    "\n",
    "vertrek_df = spark.read.csv(\n",
    "    DATADIR + \"/export_vertrek.txt\", \n",
    "    header=True,\n",
    "    sep='\\t',\n",
    "    schema=vertrek_schema\n",
    ")\n",
    "try:\n",
    "    vertrek_df.write.parquet(\"aws/vertrek.parquet\")\n",
    "except:\n",
    "    print(\"\")\n",
    "\n",
    "vertrek_df.show(3, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aankomst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aankomst_schema = StructType([\n",
    "    StructField(\"Vluchtid\", IntegerType(), False),\n",
    "    StructField(\"Vliegtuigcode\",StringType(),True),\n",
    "    StructField(\"Terminal\", StringType(), True),\n",
    "    StructField(\"Gate\", StringType(), True),\n",
    "    StructField(\"Baan\", ShortType(), True),\n",
    "    StructField(\"Bezetting\", IntegerType(), True),\n",
    "    StructField(\"Vracht\", IntegerType(), True),\n",
    "    StructField(\"Aankomsttijd\", TimestampType(), True)\n",
    "  ])\n",
    "\n",
    "aankomst_df = spark.read.csv(\n",
    "    DATADIR + \"/export_aankomst.txt\", \n",
    "    header=True,\n",
    "    sep='\\t',\n",
    "    schema=aankomst_schema\n",
    ")\n",
    "\n",
    "try:\n",
    "    aankomst_df.write.parquet(\"aws/aankomst.parquet\")\n",
    "except:\n",
    "    print(\"\")\n",
    "aankomst_df.show(3, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Planning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planning_schema = StructType([\n",
    "    StructField(\"Vluchtnr\", IntegerType(), False),\n",
    "    StructField(\"Airlinecode\", StringType(), True),\n",
    "    StructField(\"Destcode\", StringType(), True),\n",
    "    StructField(\"Planterminal\", StringType(), True),\n",
    "    StructField(\"Plangate\", StringType(), True),\n",
    "    StructField(\"Plantijd\", StringType(), True)\n",
    "  ])\n",
    "\n",
    "planning_df = spark.read.csv(\n",
    "    DATADIR + \"/export_planning.txt\", \n",
    "    header=True,\n",
    "    sep='\\t',\n",
    "    schema=planning_schema\n",
    ")\n",
    "try:\n",
    "    planning_df.write.parquet(\"aws/planning.parquet\")\n",
    "except:\n",
    "    print(\"\")\n",
    "planning_df.show(3, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Airport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_df = airport_df.dropna().collect()\n",
    "\n",
    "locations = list(map(lambda r : [r['airport'], r['city'],(r['lat'], r['lon'])], location_df)) \n",
    "map_tweets = folium.Map(location=[65,26], zoom_start=4)\n",
    "\n",
    "for location_airport, location_city, location_coords in locations:\n",
    "    folium.Circle(location=location_coords,\n",
    "                  popup = f\"{location_city}: {location_airport}\",\n",
    "                  radius = 1000,\n",
    "                  color=\"crimson\",\n",
    "                  fill_color=\"crimson\",\n",
    "                  tooltip=location_airport\n",
    "                  ).add_to(map_tweets)\n",
    "map_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operation_reviews = customers_df. groupby(\"operation\").count().dropna().sort(asc(\"operation\")).collect()\n",
    "facilities_reviews = customers_df. groupby(\"facilities\").count().dropna().sort(asc(\"facilities\")).collect()\n",
    "shops_reviews = customers_df. groupby(\"shops\").count().dropna().sort(asc(\"shops\")).collect()\n",
    "\n",
    "operation_y = list(map(lambda r : r['count'], operation_reviews))\n",
    "facilities_y = list(map(lambda r : r['count'], facilities_reviews))\n",
    "shops_y = list(map(lambda r : r['count'], shops_reviews))\n",
    "\n",
    "operation_x = list(map(lambda r : (r['operation']), operation_reviews)) \n",
    "facilities_x = list(map(lambda r : (r['facilities']), facilities_reviews)) \n",
    "shops_x = list(map(lambda r : (r['shops']), shops_reviews)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Mean: {np.mean(operation_x)}\")\n",
    "fig, ax = plt.subplots(figsize=(16,8))\n",
    "ax.plot(operation_x, operation_y)\n",
    "ax.tick_params(axis='y')\n",
    "ax.set_xlabel('Rating')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.legend()\n",
    "plt.title(\"Frequency of operation ratings\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Mean: {np.mean(facilities_x)}\")\n",
    "fig, ax = plt.subplots(figsize=(16,8))\n",
    "ax.plot(facilities_x, facilities_y)\n",
    "ax.tick_params(axis='y')\n",
    "ax.set_xlabel('Rating')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.legend()\n",
    "plt.title(\"Frequency of facility ratings\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Mean: {np.mean(shops_x)}\")\n",
    "fig, ax = plt.subplots(figsize=(16,8))\n",
    "ax.plot(shops_x, shops_y)\n",
    "ax.tick_params(axis='y')\n",
    "ax.set_xlabel('Rating')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.legend()\n",
    "plt.title(\"Frequency of shop ratings\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
